{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision \n",
    "import matplotlib.pyplot as plt \n",
    "import pathlib\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from going_modular.going_modular import data_setup,engine,utils\n",
    "from going_modular.helper_functions import download_data, set_seeds, plot_loss_curves\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict ,Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PyTorch 2 Quick Intro\n",
    "  * Reference notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/pytorch_2_intro.ipynb\n",
    "  * Reference book chapter - https://www.learnpytorch.io/pytorch_2_intro/\n",
    "  * PyTorch 2.0 release notes - https://pytorch.org/blog/pytorch-2.0-release/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PyTorch 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After PyTorch 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet50() # note: this could any model\n",
    "compiled_model = torch.compile(model)\n",
    "\n",
    "### Training code\n",
    "\n",
    "### Testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0. Getting setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current PyTorch version: 2.5.1 (should be 2.x+)\n",
      "[INFO] PyTorch 2.x installed, you'll be able to use the new features.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version\n",
    "pt_version = torch.__version__\n",
    "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "\n",
    "# Install PyTorch 2.0 if necessary\n",
    "if pt_version.split(\".\")[0] == \"1\": # Check if PyTorch version begins with 1 \n",
    "    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    print(\"[INFO] PyTorch 2.x installed, if you're on Google Colab, you may need to restart your runtime.\\\n",
    "          Though as of April 2023, Google Colab comes with PyTorch 2.0 pre-installed.\")\n",
    "    import torch\n",
    "    pt_version = torch.__version__\n",
    "    print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "else:\n",
    "    print(\"[INFO] PyTorch 2.x installed, you'll be able to use the new features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1. รับข้อมูล GPU\n",
    "เหตุใดจึงต้องรับข้อมูล GPU\n",
    "\n",
    "เนื่องจากคุณสมบัติของ PyTorch 2.0 (torch.compile()) ทำงานได้ดีที่สุดบน NVIDIA GPU รุ่นใหม่\n",
    "\n",
    "NVIDIA GPU รุ่นใหม่คืออะไร?\n",
    "\n",
    "หากต้องการทราบว่า GPU ของคุณเข้ากันได้หรือไม่ โปรดดูคะแนนความเข้ากันได้ของ NVIDIA GPU - https://developer.nvidia.com/cuda-gpus\n",
    "\n",
    "หาก GPU ของคุณมีคะแนน 8.0+ ก็สามารถใช้ประโยชน์จากฟีเจอร์ PyTorch 2.0 ใหม่ได้เกือบทั้งหมด\n",
    "\n",
    "GPU ที่ต่ำกว่า 8.0 ยังคงสามารถใช้ประโยชน์จาก PyTorch 2.0 ได้ อย่างไรก็ตาม การปรับปรุงอาจไม่สังเกตเห็นได้ชัดเจนเท่ากับรุ่น 8.0+\n",
    "\n",
    "หมายเหตุ: หากคุณสงสัยว่า GPU ใดที่คุณควรใช้สำหรับการเรียนรู้เชิงลึก โปรดดูบล็อกโพสต์ของ Tim Dettmers \" GPU ตัวใดสำหรับการเรียนรู้เชิงลึก\" - https://timdettmers.com/2023/01/30/ซึ่ง-gpu-for-deep-learning/\n",
    "\n",
    "* ในกรณีของเรา Rtx3050 ได้ 8.6 สามารถใช้ฟีเจอร์ pytorch 2.x ได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA_GeForce_RTX_3050_Laptop_GPU\n",
      "GPU capability score: (8, 6)\n",
      "GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\n",
      "GPU information:\n",
      "Mon Dec  2 22:02:26 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 561.17                 Driver Version: 561.17         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   70C    P8              7W /   63W |    2575MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     14576      C   ...onda3\\envs\\Deep_learning\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using a NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n",
    "\n",
    "  # Get GPU name\n",
    "  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n",
    "  gpu_name = gpu_name[1]\n",
    "  GPU_NAME = gpu_name.replace(\" \", \"_\") # remove underscores for easier saving\n",
    "  print(f'GPU name: {GPU_NAME}')\n",
    "\n",
    "  # Get GPU capability score\n",
    "  GPU_SCORE = torch.cuda.get_device_capability()\n",
    "  print(f\"GPU capability score: {GPU_SCORE}\")\n",
    "  if GPU_SCORE >= (8, 0):\n",
    "    print(f\"GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\")\n",
    "  else:\n",
    "    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n",
    "  \n",
    "  # Print GPU info\n",
    "  print(f\"GPU information:\\n{gpu_info}\")\n",
    "\n",
    "else:\n",
    "  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1.1 ตั้งค่าอุปกรณ์ทั่วโลก\n",
    "ก่อนหน้านี้ เราได้ตั้งค่าอุปกรณ์ของเทนเซอร์/รุ่นของเราโดยใช้ .to(device)\n",
    "\n",
    "  * tensor.to (device)\n",
    "  * model.to (device)\n",
    "\n",
    "แต่ใน PyTorch 2.0 เป็นไปได้ที่จะตั้งค่าอุปกรณ์ด้วยตัวจัดการบริบทและอุปกรณ์ส่วนกลาง - https://pytorch.org/blog/pytorch-2.0-release/#beta-torchset_default_device-and-torchdevice-as-context -ผู้จัดการ\n",
    "\n",
    "ดูเอกสาร - https://pytorch.org/tutorials/recipes/recipes/changing_default_device.html\n",
    "* แทนที่เราจะใช้ .to(device) เราสามารถประการการตั้งค่า `torch.set_default_device(device) `เพื่อที่จะได้ไม่ต้องใช้`.to`แต่เปลี่ยนเป็น`.device`แทนได้ แต้ต้องประกาศ `torch.set_default_device(\"cpu or gpu\") ` ก่อน "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights are on device: cuda:0\n",
      "Layer creating data on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "# Set the device with context manager (requires PyTorch 2.x+)\n",
    "with torch.device(device):\n",
    "  # All tensors or PyTorch objects created in the context manager will be on the target device without using .to()\n",
    "  layer = torch.nn.Linear(20, 30)\n",
    "  print(f\"Layer weights are on device: {layer.weight.device}\")\n",
    "  print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device globally (requires pytorch 2.x+)\n",
    "torch.set_default_device(\"cpu\") \n",
    "\n",
    "# All tensors or PyTorch objects created from here on out will be on the target device without using .to()\n",
    "layer = torch.nn.Linear(20, 30)\n",
    "print(f\"Layer weights are on device: {layer.weight.device}\")\n",
    "print(f\"Layer creating data on device: {layer(torch.randn(128, 20)).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "TorchVision version: 0.20.1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")\n",
    "\n",
    "# Set the target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1 Create model and transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ResNet50 from PyTorch - https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model weights and transforms\n",
    "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2 # .DEFAULT also works here\n",
    "transforms = model_weights.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: PyTorch 2.0 relative speedups will be most noticeable when as much of the GPU as possible is being used. This means a larger model (more trainable parameters) may take longer to train on the whole but will relatively faster. E.g. a model with 1M parameters may take ~10 minutes to train but a model with 25M parameters may take ~20 minutes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=10):\n",
    "  \"\"\"\n",
    "  Creates a resnet50 model with transforms and returns them both.\n",
    "  \"\"\" \n",
    "  model_weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "  transforms = model_weights.transforms()\n",
    "  model = torchvision.models.resnet50(weights=model_weights)\n",
    "\n",
    "  # Adjust the head layer to suit our number of classes\n",
    "  model.fc = torch.nn.Linear(in_features=2048,\n",
    "                             out_features=num_classes)\n",
    "\n",
    "  return model, transforms\n",
    "\n",
    "model, transforms = create_model()\n",
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2 การเร่งความเร็วจะสังเกตเห็นได้ชัดเจนที่สุดเมื่อมีการใช้ GPU ส่วนใหญ่\n",
    "เนื่องจาก GPU สมัยใหม่ดำเนินการได้รวดเร็วมาก คุณจึงมักจะสังเกตเห็นการเร่งความเร็วส่วนใหญ่ที่สัมพันธ์กันเมื่อมีข้อมูลบน GPU มากที่สุดเท่าที่จะเป็นไปได้\n",
    "\n",
    "ในทางปฏิบัติ โดยทั่วไปคุณต้องการใช้หน่วยความจำ GPU ของคุณให้ได้มากที่สุด\n",
    "\n",
    "* การเพิ่มขนาดแบตช์ - เราใช้ขนาดแบตช์ 32 แต่สำหรับ GPU ที่มีความจุหน่วยความจำมากขึ้น โดยทั่วไปคุณจะต้องการใช้ให้ใหญ่ที่สุดเท่าที่จะเป็นไปได้ เช่น 128, 256, 512 ฯลฯ\n",
    "* การเพิ่มขนาดข้อมูล - ตัวอย่างเช่น แทนที่จะใช้รูปภาพที่มีขนาด 32x32 ให้ใช้ 224x224 หรือ 336x336 นอกจากนี้คุณยังสามารถใช้ขนาดการฝังที่เพิ่มขึ้นสำหรับข้อมูลของคุณได้\n",
    "* เพิ่มขนาดโมเดล - เช่น แทนที่จะใช้โมเดลที่มีพารามิเตอร์ 1M ให้ใช้โมเดลที่มีพารามิเตอร์ 10M\n",
    "* การถ่ายโอนข้อมูลลดลง - เนื่องจากต้นทุนแบนด์วิธ (การถ่ายโอนข้อมูล) จะทำให้ GPU ช้าลง (เนื่องจากต้องการคำนวณข้อมูล)\n",
    "จากการดำเนินการข้างต้น การเร่งความเร็วสัมพัทธ์ของคุณควรดีขึ้น\n",
    "\n",
    "เช่น เวลาการฝึกโดยรวมอาจใช้เวลานานกว่าแต่ไม่เป็นเชิงเส้น\n",
    "\n",
    "แหล่งข้อมูลสำหรับการเรียนรู้วิธีปรับปรุงความเร็วของโมเดล PyTorch - https://sebastianraschka.com/blog/2023/pytorch-faster.html\n",
    "\n",
    ">หมายเหตุ: แนวคิดในการใช้ข้อมูลบน GPU ให้ได้มากที่สุดไม่ได้จำกัดเฉพาะ PyTorch 2.0 เท่านั้น แต่ยังใช้ได้กับทุกเวอร์ชันบน PyTorch และโดยทั่วไปคือทุกรุ่นที่ฝึกฝนบน GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.3 Checking the memory limits of our GPU\n",
    "Can do so using torch.cuda - https://pytorch.org/docs/stable/generated/torch.cuda.mem_get_info.html#torch.cuda.mem_get_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total free GPU memory: 0.884 GB\n",
      "Total GPU memory: 4.294 GB\n"
     ]
    }
   ],
   "source": [
    "# Check available GPU memory and total GPU memory\n",
    "total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info() \n",
    "print(f\"Total free GPU memory: {round(total_free_gpu_memory * 1e-9, 3)} GB\") \n",
    "print(f\"Total GPU memory: {round(total_gpu_memory * 1e-9, 3)} GB\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the GPU has 16GB+ of free memory, set batch size to 128\n",
    "* If the GPU has less than 16GB of free, set batch size to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory available is 0.884 GB, using batch size of 32 and image size 128\n"
     ]
    }
   ],
   "source": [
    "# Set batch size depending on amount of GPU memory\n",
    "total_free_gpu_memory_gb = round(total_free_gpu_memory * 1e-9, 3)\n",
    "if total_free_gpu_memory_gb >= 16:\n",
    "  BATCH_SIZE = 128 # Note: you could experiment with higher values here if you like.\n",
    "  IMAGE_SIZE = 224\n",
    "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "else:\n",
    "  BATCH_SIZE = 32\n",
    "  IMAGE_SIZE = 128\n",
    "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 การเพิ่มความเร็วจะเห็นได้ชัดเจนที่สุดเมื่อใช้ GPU(s) เป็นส่วนใหญ่  \n",
    "\n",
    "เนื่องจาก GPU สมัยใหม่มีความเร็วในการประมวลผลสูงมาก การเพิ่มความเร็วจะสังเกตได้ชัดเจนที่สุดเมื่อมีข้อมูลจำนวนมากถูกส่งไปให้ GPU ประมวลผล  \n",
    "\n",
    "ในทางปฏิบัติ คุณควรใช้หน่วยความจำ GPU ให้เต็มประสิทธิภาพมากที่สุดเท่าที่จะทำได้  \n",
    "\n",
    "- **เพิ่มขนาดแบตช์ (Batch size)**: เช่น หากปกติใช้ batch size 32 คุณอาจเพิ่มเป็น 128, 256 หรือ 512 หาก GPU มีหน่วยความจำมากพอ  \n",
    "- **เพิ่มขนาดข้อมูล**: เช่น แทนที่จะใช้ภาพขนาด 32x32 อาจใช้ 224x224 หรือ 336x336 รวมถึงเพิ่มขนาด embedding ของข้อมูล  \n",
    "- **เพิ่มขนาดโมเดล**: เช่น ใช้โมเดลที่มีพารามิเตอร์ 10 ล้านตัวแทนโมเดลที่มีเพียง 1 ล้านตัว  \n",
    "- **ลดการถ่ายโอนข้อมูล (Data transfer)**: เนื่องจากการถ่ายโอนข้อมูลระหว่างหน่วยความจำและ GPU มีค่าใช้จ่ายด้านแบนด์วิดท์ที่อาจทำให้ GPU ทำงานช้าลง  \n",
    "\n",
    "ด้วยการทำตามวิธีข้างต้น ความเร็วในการประมวลผลโดยรวมจะดีขึ้น แม้ว่าระยะเวลาการฝึกจะนานขึ้น แต่ไม่เพิ่มขึ้นแบบเชิงเส้น  \n",
    "\n",
    "**แหล่งเรียนรู้เพิ่มเติม**: [วิธีทำให้โมเดล PyTorch เร็วขึ้น](https://sebastianraschka.com/blog/2023/pytorch-faster.html)  \n",
    "\n",
    "หมายเหตุ: แนวคิดเรื่องการใช้ข้อมูลบน GPU ให้มากที่สุดนี้ไม่ได้จำกัดแค่ PyTorch 2.0 แต่ใช้ได้กับทุกเวอร์ชันของ PyTorch และโมเดลใด ๆ ก็ตามที่ฝึกบน GPU  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.3 Checking the memory limits of our GPU\n",
    "Can do so using `torch.cuda` - https://pytorch.org/docs/stable/generated/torch.cuda.mem_get_info.html#torch.cuda.mem_get_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available GPU memory and total GPU memory\n",
    "total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info() \n",
    "print(f\"Total free GPU memory: {round(total_free_gpu_memory * 1e-9, 3)} GB\") \n",
    "print(f\"Total GPU memory: {round(total_gpu_memory * 1e-9, 3)} GB\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the GPU has 16GB+ of free memory, set batch size to 128\n",
    "* If the GPU has less than 16GB of free, set batch size to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size depending on amount of GPU memory\n",
    "total_free_gpu_memory_gb = round(total_free_gpu_memory * 1e-9, 3)\n",
    "if total_free_gpu_memory_gb >= 16:\n",
    "  BATCH_SIZE = 128 # Note: you could experiment with higher values here if you like.\n",
    "  IMAGE_SIZE = 224\n",
    "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "else:\n",
    "  BATCH_SIZE = 32\n",
    "  IMAGE_SIZE = 128\n",
    "  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data transforms:\n",
      "ImageClassification(\n",
      "    crop_size=128\n",
      "    resize_size=128\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transforms.crop_size = 128\n",
    "transforms.resize_size = 128 \n",
    "print(f\"Updated data transforms:\\n{transforms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 การเพิ่มความเร็วเพิ่มเติมด้วย TF32  \n",
    "\n",
    "**TF32 (TensorFloat32)**  \n",
    "TF32 เป็นชนิดข้อมูลที่อยู่กึ่งกลางระหว่าง **Float32** และ **Float16**  \n",
    "\n",
    "- **Float32**: ตัวเลขถูกแทนด้วย 32 ไบต์ (เช่น 010101010110011 = 7)  \n",
    "- **Float16**: ตัวเลขถูกแทนด้วย 16 ไบต์ (เช่น 01010101 = 4)  \n",
    "\n",
    "**เป้าหมาย**:  \n",
    "1. ทำให้การฝึกโมเดลเร็วขึ้น  \n",
    "2. ทำให้การฝึกโมเดลมีความแม่นยำ  \n",
    "\n",
    "TF32 เป็นชนิดข้อมูลที่พัฒนาโดย NVIDIA ซึ่งรวมข้อดีของ Float32 และ Float16 เข้าไว้ด้วยกัน  \n",
    "\n",
    "TF32 ใช้งานได้กับ GPU สถาปัตยกรรม Ampere ขึ้นไป  \n",
    "\n",
    "**เรียนรู้เพิ่มเติมเกี่ยวกับความแม่นยำ**: [Precision (Computer Science)](https://en.wikipedia.org/wiki/Precision_(computer_science))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision ในการคำนวณ**  \n",
    "**Precision** คือความสามารถในการแทนค่าตัวเลขได้อย่างแม่นยำในหน่วยความจำหรือการคำนวณ  \n",
    "\n",
    "- คิดเหมือนกับ **ท่อ**:  \n",
    "  - **ท่อใหญ่ (Float32)**: เก็บน้ำ (ข้อมูล) ได้เยอะและละเอียด  \n",
    "  - **ท่อเล็ก (Float16)**: เก็บน้ำได้น้อยกว่าและอาจไม่ละเอียดพอ  \n",
    "  - **ท่อพอดี (TF32)**: เก็บน้ำได้เพียงพอและยังไหลเร็ว  \n",
    "\n",
    "**ตัวอย่าง**:  \n",
    "- Float32 = แม่นยำมากแต่ช้ากว่า  \n",
    "- Float16 = เร็วแต่ไม่แม่นยำพอ  \n",
    "- TF32 = สมดุลระหว่างความเร็วและความแม่นยำ  \n",
    "\n",
    "**ผล**: Precision ส่งผลต่อความเร็วและคุณภาพของการประมวลผลโดยตรง!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU_SCORE >= (8, 0): # check if GPU is compatiable with TF32\n",
    "  print(f\"[INFO] Using GPU with score: {GPU_SCORE}, enabling TensorFloat32\")\n",
    "  torch.backends.cuda.matmul.allow_tf32 = True\n",
    "else:\n",
    "  print(f\"[INFO] Using GPU with score: {GPU_SCORE}, TensorFloat32 not available\") \n",
    "  torch.backends.cuda.matmul.allow_tf32 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.5 Preparing datasets\n",
    "As before, we discussed we're going to use CIFAR10.\n",
    "\n",
    "Homepage - https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "We can download the dataset from torchvision - https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:20<00:00, 8.47MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .\\cifar-10-python.tar.gz to .\n",
      "Files already downloaded and verified\n",
      "[INFO] Train dataset length: 50000\n",
      "[INFO] test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=\".\",\n",
    "                                             train=True,\n",
    "                                             download=True,\n",
    "                                             transform=transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\".\",\n",
    "                                             train=False,\n",
    "                                             download=True,\n",
    "                                             transform=transforms)\n",
    "#Get len(dataset)\n",
    "train_len = len(train_dataset)\n",
    "test_len = len(test_dataset)\n",
    "print(f\"[INFO] Train dataset length: {train_len}\")\n",
    "print(f\"[INFO] test dataset length: {test_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.6 Create Dataloaders\n",
    "\n",
    "Next:\n",
    " * Turn datasets into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader num batches: 1563 of batch size: 32\n",
      "Test dataloader num batches: 313 of batch size: 32\n",
      "Using num workers to load data (more is generally better): 16\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "NUM_WORKERS = os.cpu_count() # we want highest number of CPU cores to load data to GPU \n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKERS)\n",
    "\n",
    "# Print details:\n",
    "print(f\"Train dataloader num batches: {len(train_dataloader)} of batch size: {BATCH_SIZE}\")\n",
    "print(f\"Test dataloader num batches: {len(test_dataloader)} of batch size: {BATCH_SIZE}\")\n",
    "print(f\"Using num workers to load data (more is generally better): {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 Creating training and test loops\n",
    "Want to create:\n",
    "\n",
    "Training and test loops + a timing step for each, so we know how long our models take to train/test We covered this functionality in previous sections, one is here: https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(epoch: int,\n",
    "               model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device,\n",
    "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        desc=f\"Training Epoch {epoch}\", \n",
    "        total=len(dataloader),\n",
    "        disable=disable_progress_bar\n",
    "    )\n",
    "\n",
    "  for batch, (X, y) in progress_bar:\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metrics across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "      # Update progress bar\n",
    "      progress_bar.set_postfix(\n",
    "            {\n",
    "                \"train_loss\": train_loss / (batch + 1),\n",
    "                \"train_acc\": train_acc / (batch + 1),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(epoch: int,\n",
    "              model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device,\n",
    "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  progress_bar = tqdm(\n",
    "      enumerate(dataloader), \n",
    "      desc=f\"Testing Epoch {epoch}\", \n",
    "      total=len(dataloader),\n",
    "      disable=disable_progress_bar\n",
    "  )\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.no_grad(): # no_grad() required for PyTorch 2.0, I found some errors with `torch.inference_mode()`, please let me know if this is not the case\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in progress_bar:\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "          # Update progress bar\n",
    "          progress_bar.set_postfix(\n",
    "              {\n",
    "                  \"test_loss\": test_loss / (batch + 1),\n",
    "                  \"test_acc\": test_acc / (batch + 1),\n",
    "              }\n",
    "          )\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": [],\n",
    "      \"train_epoch_time\": [],\n",
    "      \"test_epoch_time\": []\n",
    "  }\n",
    "\n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
    "\n",
    "      # Perform training step and time it\n",
    "      train_epoch_start_time = time.time()\n",
    "      train_loss, train_acc = train_step(epoch=epoch, \n",
    "                                        model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        device=device,\n",
    "                                        disable_progress_bar=disable_progress_bar)\n",
    "      train_epoch_end_time = time.time()\n",
    "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
    "      \n",
    "      # Perform testing step and time it\n",
    "      test_epoch_start_time = time.time()\n",
    "      test_loss, test_acc = test_step(epoch=epoch,\n",
    "                                      model=model,\n",
    "                                      dataloader=test_dataloader,\n",
    "                                      loss_fn=loss_fn,\n",
    "                                      device=device,\n",
    "                                      disable_progress_bar=disable_progress_bar)\n",
    "      test_epoch_end_time = time.time()\n",
    "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f} | \"\n",
    "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
    "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
    "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3. Time models across a single run\n",
    "Experiment 1: single run without torch.compile() for 5 epochs\n",
    "\n",
    "3.1 Experiment 1 - Single run, no compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 1563/1563 [03:57<00:00,  6.58it/s, train_loss=1.13, train_acc=0.6]\n",
      "Testing Epoch 0: 100%|██████████| 313/313 [00:16<00:00, 19.24it/s, test_loss=0.83, test_acc=0.712]\n",
      " 20%|██        | 1/5 [07:44<30:58, 464.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1260 | train_acc: 0.6001 | test_loss: 0.8301 | test_acc: 0.7121 | train_epoch_time: 356.2934 | test_epoch_time: 108.2656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 1563/1563 [03:50<00:00,  6.79it/s, train_loss=0.68, train_acc=0.765]\n",
      "Testing Epoch 1: 100%|██████████| 313/313 [00:17<00:00, 18.37it/s, test_loss=0.64, test_acc=0.78]\n",
      " 40%|████      | 2/5 [15:22<23:02, 460.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.6801 | train_acc: 0.7650 | test_loss: 0.6404 | test_acc: 0.7804 | train_epoch_time: 335.5506 | test_epoch_time: 122.5391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 1563/1563 [03:45<00:00,  6.92it/s, train_loss=0.518, train_acc=0.823]\n",
      "Testing Epoch 2: 100%|██████████| 313/313 [00:17<00:00, 17.89it/s, test_loss=0.573, test_acc=0.809]\n",
      " 60%|██████    | 3/5 [22:59<15:17, 458.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.5178 | train_acc: 0.8228 | test_loss: 0.5733 | test_acc: 0.8092 | train_epoch_time: 340.3359 | test_epoch_time: 116.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 1563/1563 [03:54<00:00,  6.67it/s, train_loss=0.408, train_acc=0.859]\n",
      "Testing Epoch 3: 100%|██████████| 313/313 [00:16<00:00, 18.92it/s, test_loss=0.563, test_acc=0.818]\n",
      " 80%|████████  | 4/5 [30:44<07:41, 461.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.4082 | train_acc: 0.8586 | test_loss: 0.5632 | test_acc: 0.8176 | train_epoch_time: 356.3575 | test_epoch_time: 109.5141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 1563/1563 [03:50<00:00,  6.79it/s, train_loss=0.32, train_acc=0.889]\n",
      "Testing Epoch 4: 100%|██████████| 313/313 [00:17<00:00, 18.24it/s, test_loss=0.504, test_acc=0.84]\n",
      "100%|██████████| 5/5 [38:21<00:00, 460.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3204 | train_acc: 0.8886 | test_loss: 0.5044 | test_acc: 0.8402 | train_epoch_time: 346.0302 | test_epoch_time: 110.8193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, _ = create_model() # _ จะเก็บค่า \"extra_info\" แต่ไม่ได้ใช้งานจริง\n",
    "model.to(device)\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the classifier head of the pretrained resnet50 feature extractor model\n",
    "\n",
    "single_run_no_compile_results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 Experiment 2, single, using torch.compile()\n",
    "Same setup as experiment 1 except with the new line `torch.compile().`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_LOGS=\"+dynamo\"\n",
    "TORCHDYNAMO_VERBOSE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchDynamo is working!\n"
     ]
    }
   ],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.verbose = True\n",
    "print(\"TorchDynamo is working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compile: 0.0009999275207519531 | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torchvision\\models\\resnet.py line 284\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] ========== TorchDynamo Stack Trace ==========\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:32.150000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT _forward_impl c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torchvision\\models\\resnet.py line 266\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] ========== TorchDynamo Stack Trace ==========\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:51.752000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torchvision\\models\\resnet.py line 143\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] ========== TorchDynamo Stack Trace ==========\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\ProgramData\\anaconda3\\envs\\Deep_learning\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1202 22:42:53.300000 14576 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "Training Epoch 0: 100%|██████████| 1563/1563 [05:56<00:00,  4.39it/s, train_loss=1.09, train_acc=0.613]\n",
      "Testing Epoch 0: 100%|██████████| 313/313 [00:17<00:00, 17.42it/s, test_loss=0.816, test_acc=0.719]\n",
      " 20%|██        | 1/5 [09:38<38:32, 578.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0868 | train_acc: 0.6132 | test_loss: 0.8158 | test_acc: 0.7188 | train_epoch_time: 459.3545 | test_epoch_time: 118.8215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 1563/1563 [03:45<00:00,  6.93it/s, train_loss=0.68, train_acc=0.763]\n",
      "Testing Epoch 1: 100%|██████████| 313/313 [00:17<00:00, 18.34it/s, test_loss=0.594, test_acc=0.795]\n",
      " 40%|████      | 2/5 [16:57<24:49, 496.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.6796 | train_acc: 0.7634 | test_loss: 0.5941 | test_acc: 0.7953 | train_epoch_time: 328.5945 | test_epoch_time: 110.5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 1563/1563 [04:09<00:00,  6.26it/s, train_loss=0.517, train_acc=0.822]\n",
      "Testing Epoch 2: 100%|██████████| 313/313 [00:17<00:00, 18.26it/s, test_loss=0.6, test_acc=0.797]\n",
      " 60%|██████    | 3/5 [24:34<15:57, 478.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.5169 | train_acc: 0.8222 | test_loss: 0.6005 | test_acc: 0.7965 | train_epoch_time: 350.1488 | test_epoch_time: 107.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 1563/1563 [03:48<00:00,  6.85it/s, train_loss=0.414, train_acc=0.857]\n",
      "Testing Epoch 3: 100%|██████████| 313/313 [00:17<00:00, 18.16it/s, test_loss=0.469, test_acc=0.841]\n",
      " 80%|████████  | 4/5 [32:15<07:51, 471.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.4137 | train_acc: 0.8572 | test_loss: 0.4689 | test_acc: 0.8406 | train_epoch_time: 340.8755 | test_epoch_time: 120.3394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 1563/1563 [03:48<00:00,  6.84it/s, train_loss=0.324, train_acc=0.887]\n",
      "Testing Epoch 4: 100%|██████████| 313/313 [00:17<00:00, 18.00it/s, test_loss=0.508, test_acc=0.825]\n",
      "100%|██████████| 5/5 [39:54<00:00, 478.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3245 | train_acc: 0.8870 | test_loss: 0.5084 | test_acc: 0.8246 | train_epoch_time: 335.4142 | test_epoch_time: 123.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create model and transforms\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.verbose = True\n",
    "TORCH_LOGS=\"+dynamo\"\n",
    "TORCHDYNAMO_VERBOSE=1\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "model, transforms = create_model()\n",
    "model.to(device)\n",
    "\n",
    "# Create loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "# Compile the model and time how long it takes\n",
    "compile_start_time = time.time()\n",
    "\n",
    "### New in PyTorch 2.x ###\n",
    "compiled_model = torch.compile(model)\n",
    "##########################\n",
    "\n",
    "compile_end_time = time.time()\n",
    "compile_time = compile_end_time - compile_start_time\n",
    "print(f\"Time to compile: {compile_time} | Note: The first time you compile your model, the first few epochs will be slower than subsequent runs.\")\n",
    "\n",
    "# Train the compiled model\n",
    "single_run_compile_results = train(model=compiled_model,\n",
    "                                   train_dataloader=train_dataloader,\n",
    "                                   test_dataloader=test_dataloader,\n",
    "                                   loss_fn=loss_fn,\n",
    "                                   optimizer=optimizer,\n",
    "                                   epochs=NUM_EPOCHS,\n",
    "                                   device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.3 Compare the results of experiment 1 and 2\n",
    "Nice!\n",
    "\n",
    "We've got two trained models:\n",
    "\n",
    "1. One without torch.compile().\n",
    "2. One with torch.compile().\n",
    "Let's compare the results of each experiment.\n",
    "\n",
    "To do so, we'll first create dataframes of the results of each.\n",
    "\n",
    "Then we'll plot the results of each experiment on a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "single_run_no_compile_results_df = pd.DataFrame(single_run_no_compile_results)\n",
    "single_run_compile_results_df = pd.DataFrame(single_run_compile_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.126034</td>\n",
       "      <td>0.600068</td>\n",
       "      <td>0.830110</td>\n",
       "      <td>0.712061</td>\n",
       "      <td>356.293426</td>\n",
       "      <td>108.265562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680057</td>\n",
       "      <td>0.764995</td>\n",
       "      <td>0.640422</td>\n",
       "      <td>0.780351</td>\n",
       "      <td>335.550642</td>\n",
       "      <td>122.539122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517773</td>\n",
       "      <td>0.822817</td>\n",
       "      <td>0.573253</td>\n",
       "      <td>0.809205</td>\n",
       "      <td>340.335937</td>\n",
       "      <td>116.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408160</td>\n",
       "      <td>0.858625</td>\n",
       "      <td>0.563227</td>\n",
       "      <td>0.817592</td>\n",
       "      <td>356.357491</td>\n",
       "      <td>109.514078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320353</td>\n",
       "      <td>0.888616</td>\n",
       "      <td>0.504355</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>346.030156</td>\n",
       "      <td>110.819316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.126034   0.600068   0.830110  0.712061        356.293426   \n",
       "1    0.680057   0.764995   0.640422  0.780351        335.550642   \n",
       "2    0.517773   0.822817   0.573253  0.809205        340.335937   \n",
       "3    0.408160   0.858625   0.563227  0.817592        356.357491   \n",
       "4    0.320353   0.888616   0.504355  0.840156        346.030156   \n",
       "\n",
       "   test_epoch_time  \n",
       "0       108.265562  \n",
       "1       122.539122  \n",
       "2       116.060200  \n",
       "3       109.514078  \n",
       "4       110.819316  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the head of one of the results dataframes\n",
    "single_run_no_compile_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.086804</td>\n",
       "      <td>0.613184</td>\n",
       "      <td>0.815784</td>\n",
       "      <td>0.718850</td>\n",
       "      <td>459.354481</td>\n",
       "      <td>118.821549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.679591</td>\n",
       "      <td>0.763396</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>0.795327</td>\n",
       "      <td>328.594486</td>\n",
       "      <td>110.520266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.516925</td>\n",
       "      <td>0.822237</td>\n",
       "      <td>0.600489</td>\n",
       "      <td>0.796526</td>\n",
       "      <td>350.148842</td>\n",
       "      <td>107.211611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.413695</td>\n",
       "      <td>0.857206</td>\n",
       "      <td>0.468937</td>\n",
       "      <td>0.840555</td>\n",
       "      <td>340.875472</td>\n",
       "      <td>120.339366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.324479</td>\n",
       "      <td>0.887036</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>335.414204</td>\n",
       "      <td>123.078380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.086804   0.613184   0.815784  0.718850        459.354481   \n",
       "1    0.679591   0.763396   0.594100  0.795327        328.594486   \n",
       "2    0.516925   0.822237   0.600489  0.796526        350.148842   \n",
       "3    0.413695   0.857206   0.468937  0.840555        340.875472   \n",
       "4    0.324479   0.887036   0.508399  0.824581        335.414204   \n",
       "\n",
       "   test_epoch_time  \n",
       "0       118.821549  \n",
       "1       110.520266  \n",
       "2       107.211611  \n",
       "3       120.339366  \n",
       "4       123.078380  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_run_compile_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filename to save the results\n",
    "DATASET_NAME = \"CIFAR10\"\n",
    "MODEL_NAME = \"ResNet50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_mean_epoch_times(non_compiled_results: pd.DataFrame, \n",
    "                          compiled_results: pd.DataFrame, \n",
    "                          multi_runs: bool=False, \n",
    "                          num_runs: int=0, \n",
    "                          save: bool=False, \n",
    "                          save_path: str=\"\",\n",
    "                          dataset_name: str=DATASET_NAME,\n",
    "                          model_name: str=MODEL_NAME,\n",
    "                          num_epochs: int=NUM_EPOCHS,\n",
    "                          image_size: int=IMAGE_SIZE,\n",
    "                          batch_size: int=BATCH_SIZE) -> plt.figure:\n",
    "    \n",
    "    # Get the mean epoch times from the non-compiled models\n",
    "    mean_train_epoch_time = non_compiled_results.train_epoch_time.mean()\n",
    "    mean_test_epoch_time = non_compiled_results.test_epoch_time.mean()\n",
    "    mean_results = [mean_train_epoch_time, mean_test_epoch_time]\n",
    "\n",
    "    # Get the mean epoch times from the compiled models\n",
    "    mean_compile_train_epoch_time = compiled_results.train_epoch_time.mean()\n",
    "    mean_compile_test_epoch_time = compiled_results.test_epoch_time.mean()\n",
    "    mean_compile_results = [mean_compile_train_epoch_time, mean_compile_test_epoch_time]\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile train epoch times\n",
    "    train_epoch_time_diff = mean_compile_train_epoch_time - mean_train_epoch_time\n",
    "    train_epoch_time_diff_percent = (train_epoch_time_diff / mean_train_epoch_time) * 100\n",
    "\n",
    "    # Calculate the percentage difference between the mean compile and non-compile test epoch times\n",
    "    test_epoch_time_diff = mean_compile_test_epoch_time - mean_test_epoch_time\n",
    "    test_epoch_time_diff_percent = (test_epoch_time_diff / mean_test_epoch_time) * 100\n",
    "\n",
    "    # Print the mean difference percentages\n",
    "    print(f\"Mean train epoch time difference: {round(train_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "    print(f\"Mean test epoch time difference: {round(test_epoch_time_diff_percent, 3)}% (negative means faster)\")\n",
    "\n",
    "    # Create a bar plot of the mean train and test epoch time for both compiled and non-compiled models\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    width = 0.3\n",
    "    x_indicies = np.arange(len(mean_results))\n",
    "\n",
    "    plt.bar(x=x_indicies, height=mean_results, width=width, label=\"non_compiled_results\")\n",
    "    plt.bar(x=x_indicies + width, height=mean_compile_results, width=width, label=\"compiled_results\")\n",
    "    plt.xticks(x_indicies + width / 2, (\"Train Epoch\", \"Test Epoch\"))\n",
    "    plt.ylabel(\"Mean epoch time (seconds, lower is better)\")\n",
    "\n",
    "    # Create the title based on the parameters passed to the function\n",
    "    if multi_runs:\n",
    "        plt.suptitle(\"Multiple run results\")\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {num_epochs} ({num_runs} runs) | Data: {dataset_name} | Model: {model_name} | Image size: {image_size} | Batch size: {batch_size}\")\n",
    "    else:\n",
    "        plt.suptitle(\"Single run results\")\n",
    "        plt.title(f\"GPU: {gpu_name} | Epochs: {num_epochs} | Data: {dataset_name} | Model: {model_name} | Image size: {image_size} | Batch size: {batch_size}\")\n",
    "    plt.legend();\n",
    "\n",
    "    # Save the figure\n",
    "    if save:\n",
    "        assert save_path != \"\", \"Please specify a save path to save the model figure to via the save_path parameter.\"\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"[INFO] Plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Save path for single run results: pytorch_2_results/figures/single_run_NVIDIA_GeForce_RTX_3050_Laptop_GPU_ResNet50_CIFAR10_128_train_epoch_time.png\n",
      "Mean train epoch time difference: 4.602% (negative means faster)\n",
      "Mean test epoch time difference: 2.252% (negative means faster)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_to_save_figures_in = \"pytorch_2_results/figures/\"\n",
    "os.makedirs(dir_to_save_figures_in, exist_ok=True)\n",
    "\n",
    "# Create a save path for the single run results\n",
    "save_path_single_run = f\"{dir_to_save_figures_in}single_run_{GPU_NAME}_{MODEL_NAME}_{DATASET_NAME}_{IMAGE_SIZE}_train_epoch_time.png\"\n",
    "print(f\"[INFO] Save path for single run results: {save_path_single_run}\")\n",
    "\n",
    "#plot the results and save the figure(s)\n",
    "plot_mean_epoch_times(non_compiled_results=single_run_no_compile_results_df,\n",
    "                      compiled_results=single_run_compile_results_df,\n",
    "                      multi_runs=False,\n",
    "                      save_path=save_path_single_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.4 Save single run results to file with GPU details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving non-compiled experiment 1 results to: pytorch_2_results/single_run_results/single_run_non_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_3050_Laptop_GPU.csv\n",
      "[INFO] Saving compiled experiment 2 results to: pytorch_2_results/single_run_results/single_run_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_3050_Laptop_GPU.csv\n"
     ]
    }
   ],
   "source": [
    "# Make a directory for single_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_single_run_results_dir = f\"{pytorch_2_results_dir}/single_run_results\"\n",
    "os.makedirs(pytorch_2_single_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Create filenames for each of the dataframes\n",
    "save_name_for_non_compiled_results = f\"single_run_non_compiled_results_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME}.csv\"\n",
    "save_name_for_compiled_results = f\"single_run_compiled_results_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME}.csv\"\n",
    "\n",
    "# Create filepaths to save the results to\n",
    "single_run_no_compile_save_path = f\"{pytorch_2_single_run_results_dir}/{save_name_for_non_compiled_results}\"\n",
    "single_run_compile_save_path = f\"{pytorch_2_single_run_results_dir}/{save_name_for_compiled_results}\"\n",
    "print(f\"[INFO] Saving non-compiled experiment 1 results to: {single_run_no_compile_save_path}\")\n",
    "print(f\"[INFO] Saving compiled experiment 2 results to: {single_run_compile_save_path}\")\n",
    "\n",
    "# Save the results\n",
    "single_run_no_compile_results_df.to_csv(single_run_no_compile_save_path)\n",
    "single_run_compile_results_df.to_csv(single_run_compile_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4. Time models across multiple runs\n",
    "Time for multi-run experiments!\n",
    "\n",
    "  * Experiment 3 - 3x5 epochs without torch.compile()\n",
    "  * Experiment 4 - 3x5 epochs with torch.compile()\n",
    "Before running experiment 3 and 4, let's create 3 functions:\n",
    "\n",
    "  1. Experiment 3: create_and_train_non_compiled_model() - creates and trains a model for a single run (can put this function in a loop for mulitple runs).\n",
    "  2. Experiment 4: create_compiled_model() - creates and compiles a model, returns the compiled model.\n",
    "  3. Experiment 4: train_compiled_model() - trains a compiled model for a single run (can put this in a loop to train for multiple runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_non_compiled_model(epochs=NUM_EPOCHS,\n",
    "                                        learning_rate=LEARNING_RATE,\n",
    "                                        disable_progress_bar=False): \n",
    "\n",
    "    \"\"\"\n",
    "    Create and train a non-compiled PyTorch model.\n",
    "    \"\"\"\n",
    "    model, _ = create_model()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=learning_rate)\n",
    "    \n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    epochs=epochs,\n",
    "                    device=device,\n",
    "                    disable_progress_bar=disable_progress_bar)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_compiled_model():\n",
    "  \"\"\"\n",
    "  Create a compiled PyTorch model and return it.\n",
    "  \"\"\" \n",
    "  model, _ = create_model()\n",
    "  model.to(device)\n",
    "\n",
    "  compile_start_time = time.time()\n",
    "\n",
    "  ### New in PyTorch 2.0!!! ###\n",
    "  compiled_model = torch.compile(model)\n",
    "\n",
    "  compile_end_time = time.time()\n",
    "\n",
    "  compile_time = compile_end_time - compile_start_time\n",
    "\n",
    "  print(f\"[INFO] Model compile time: {compile_time}\")\n",
    "\n",
    "  return compiled_model\n",
    "\n",
    "def train_compiled_model(model=compiled_model,\n",
    "                         epochs=NUM_EPOCHS,\n",
    "                         learning_rate=LEARNING_RATE,\n",
    "                         disable_progress_bar=False):\n",
    "  \"\"\"\n",
    "  Train a compiled model and return the results.\n",
    "  \"\"\" \n",
    "  loss_fn = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(compiled_model.parameters(),\n",
    "                               lr=learning_rate)\n",
    "  \n",
    "  compile_results = train(model=model,\n",
    "                          train_dataloader=train_dataloader,\n",
    "                          test_dataloader=test_dataloader,\n",
    "                          loss_fn=loss_fn,\n",
    "                          optimizer=optimizer,\n",
    "                          epochs=epochs,\n",
    "                          device=device,\n",
    "                          disable_progress_bar=disable_progress_bar)\n",
    "\n",
    "  return compile_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.0893 | train_acc: 0.6116 | test_loss: 0.8261 | test_acc: 0.7150 | train_epoch_time: 299.5057 | test_epoch_time: 98.1829\n",
      "Epoch: 2 | train_loss: 0.6599 | train_acc: 0.7720 | test_loss: 0.6722 | test_acc: 0.7727 | train_epoch_time: 311.3335 | test_epoch_time: 105.3801\n",
      "Epoch: 3 | train_loss: 0.5069 | train_acc: 0.8254 | test_loss: 0.5555 | test_acc: 0.8098 | train_epoch_time: 452.6944 | test_epoch_time: 102.8243\n",
      "Epoch: 4 | train_loss: 0.4027 | train_acc: 0.8615 | test_loss: 0.5306 | test_acc: 0.8212 | train_epoch_time: 445.9756 | test_epoch_time: 102.8739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [41:07<1:22:14, 2467.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3181 | train_acc: 0.8891 | test_loss: 0.4777 | test_acc: 0.8452 | train_epoch_time: 444.7607 | test_epoch_time: 103.2369\n",
      "[INFO] Run 2 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.2272 | train_acc: 0.5633 | test_loss: 0.9373 | test_acc: 0.6733 | train_epoch_time: 446.3747 | test_epoch_time: 99.9983\n",
      "Epoch: 2 | train_loss: 0.7552 | train_acc: 0.7391 | test_loss: 0.7637 | test_acc: 0.7491 | train_epoch_time: 445.4625 | test_epoch_time: 99.8072\n",
      "Epoch: 3 | train_loss: 0.5685 | train_acc: 0.8046 | test_loss: 0.5640 | test_acc: 0.8023 | train_epoch_time: 435.2033 | test_epoch_time: 100.2739\n",
      "Epoch: 4 | train_loss: 0.4445 | train_acc: 0.8467 | test_loss: 0.5499 | test_acc: 0.8153 | train_epoch_time: 437.3259 | test_epoch_time: 99.4646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [1:26:11<43:26, 2606.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3584 | train_acc: 0.8755 | test_loss: 0.5025 | test_acc: 0.8312 | train_epoch_time: 439.7248 | test_epoch_time: 100.3063\n",
      "[INFO] Run 3 of 3 for non-compiled model\n",
      "Epoch: 1 | train_loss: 1.1367 | train_acc: 0.5946 | test_loss: 0.8132 | test_acc: 0.7227 | train_epoch_time: 440.4763 | test_epoch_time: 100.2339\n",
      "Epoch: 2 | train_loss: 0.6845 | train_acc: 0.7622 | test_loss: 0.6452 | test_acc: 0.7801 | train_epoch_time: 439.2468 | test_epoch_time: 99.5823\n",
      "Epoch: 3 | train_loss: 0.5253 | train_acc: 0.8168 | test_loss: 0.5617 | test_acc: 0.8017 | train_epoch_time: 440.6409 | test_epoch_time: 100.3712\n",
      "Epoch: 4 | train_loss: 0.4117 | train_acc: 0.8586 | test_loss: 0.5089 | test_acc: 0.8308 | train_epoch_time: 439.4755 | test_epoch_time: 100.5382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [2:11:13<00:00, 2624.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3225 | train_acc: 0.8889 | test_loss: 0.5052 | test_acc: 0.8330 | train_epoch_time: 440.6519 | test_epoch_time: 99.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run non-compiled model for multiple runs\n",
    "NUM_RUNS = 3\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Create an empty list to store multiple run results\n",
    "non_compile_results_multiple_runs = []\n",
    "\n",
    "# Run non-compiled model for multiple runs\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for non-compiled model\")\n",
    "    results = create_and_train_non_compiled_model(epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    non_compile_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.151057</td>\n",
       "      <td>0.589851</td>\n",
       "      <td>0.858888</td>\n",
       "      <td>0.703674</td>\n",
       "      <td>395.452212</td>\n",
       "      <td>99.471706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.699830</td>\n",
       "      <td>0.757764</td>\n",
       "      <td>0.693654</td>\n",
       "      <td>0.767272</td>\n",
       "      <td>398.680918</td>\n",
       "      <td>101.589837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533572</td>\n",
       "      <td>0.815606</td>\n",
       "      <td>0.560394</td>\n",
       "      <td>0.804613</td>\n",
       "      <td>442.846216</td>\n",
       "      <td>101.156436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.419616</td>\n",
       "      <td>0.855626</td>\n",
       "      <td>0.529803</td>\n",
       "      <td>0.822417</td>\n",
       "      <td>440.925649</td>\n",
       "      <td>100.958890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333009</td>\n",
       "      <td>0.884497</td>\n",
       "      <td>0.495133</td>\n",
       "      <td>0.836462</td>\n",
       "      <td>441.712479</td>\n",
       "      <td>101.158446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    1.151057   0.589851   0.858888  0.703674        395.452212   \n",
       "1    0.699830   0.757764   0.693654  0.767272        398.680918   \n",
       "2    0.533572   0.815606   0.560394  0.804613        442.846216   \n",
       "3    0.419616   0.855626   0.529803  0.822417        440.925649   \n",
       "4    0.333009   0.884497   0.495133  0.836462        441.712479   \n",
       "\n",
       "   test_epoch_time  \n",
       "0        99.471706  \n",
       "1       101.589837  \n",
       "2       101.156436  \n",
       "3       100.958890  \n",
       "4       101.158446  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through non_compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "non_compile_results_dfs = []\n",
    "for result in non_compile_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    non_compile_results_dfs.append(result_df)\n",
    "non_compile_results_multiple_runs_df = pd.concat(non_compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "non_compile_results_multiple_runs_df = non_compile_results_multiple_runs_df.groupby(non_compile_results_multiple_runs_df.index).mean()\n",
    "non_compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model compile time: 0.011484146118164062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Run 1 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 1.1399 | train_acc: 0.5934 | test_loss: 0.8302 | test_acc: 0.7143 | train_epoch_time: 440.9326 | test_epoch_time: 100.4997\n",
      "Epoch: 2 | train_loss: 0.7070 | train_acc: 0.7569 | test_loss: 0.6555 | test_acc: 0.7710 | train_epoch_time: 441.3448 | test_epoch_time: 100.6253\n",
      "Epoch: 3 | train_loss: 0.5456 | train_acc: 0.8123 | test_loss: 0.5524 | test_acc: 0.8084 | train_epoch_time: 440.4625 | test_epoch_time: 100.5860\n",
      "Epoch: 4 | train_loss: 0.4253 | train_acc: 0.8528 | test_loss: 0.5451 | test_acc: 0.8205 | train_epoch_time: 441.4580 | test_epoch_time: 100.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [45:11<1:30:23, 2711.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3359 | train_acc: 0.8838 | test_loss: 0.5239 | test_acc: 0.8329 | train_epoch_time: 445.6766 | test_epoch_time: 100.2872\n",
      "[INFO] Run 2 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.2890 | train_acc: 0.8990 | test_loss: 0.5041 | test_acc: 0.8349 | train_epoch_time: 445.4627 | test_epoch_time: 100.2164\n",
      "Epoch: 2 | train_loss: 0.2058 | train_acc: 0.9280 | test_loss: 0.5185 | test_acc: 0.8444 | train_epoch_time: 449.9926 | test_epoch_time: 101.3357\n",
      "Epoch: 3 | train_loss: 0.1523 | train_acc: 0.9467 | test_loss: 0.5084 | test_acc: 0.8539 | train_epoch_time: 353.0010 | test_epoch_time: 108.3729\n",
      "Epoch: 4 | train_loss: 0.1233 | train_acc: 0.9567 | test_loss: 0.5691 | test_acc: 0.8475 | train_epoch_time: 311.0024 | test_epoch_time: 111.4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [1:25:18<42:12, 2532.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.0966 | train_acc: 0.9657 | test_loss: 0.5619 | test_acc: 0.8548 | train_epoch_time: 317.6446 | test_epoch_time: 108.4541\n",
      "[INFO] Run 3 of 3 for compiled model\n",
      "Epoch: 1 | train_loss: 0.0968 | train_acc: 0.9670 | test_loss: 0.6013 | test_acc: 0.8522 | train_epoch_time: 314.5010 | test_epoch_time: 104.9355\n",
      "Epoch: 2 | train_loss: 0.0788 | train_acc: 0.9722 | test_loss: 0.5789 | test_acc: 0.8547 | train_epoch_time: 315.7265 | test_epoch_time: 105.2174\n",
      "Epoch: 3 | train_loss: 0.0687 | train_acc: 0.9763 | test_loss: 0.6220 | test_acc: 0.8525 | train_epoch_time: 313.7326 | test_epoch_time: 105.7897\n",
      "Epoch: 4 | train_loss: 0.0695 | train_acc: 0.9759 | test_loss: 0.6124 | test_acc: 0.8597 | train_epoch_time: 313.4985 | test_epoch_time: 108.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [2:00:27<00:00, 2409.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.0598 | train_acc: 0.9792 | test_loss: 0.6061 | test_acc: 0.8623 | train_epoch_time: 319.2489 | test_epoch_time: 107.3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create compiled model\n",
    "compiled_model = create_compiled_model()\n",
    "\n",
    "# Create an empty list to store compiled model results\n",
    "compiled_results_multiple_runs = []\n",
    "\n",
    "# Run compiled model for multiple runs\n",
    "for i in tqdm(range(NUM_RUNS)):\n",
    "    print(f\"[INFO] Run {i+1} of {NUM_RUNS} for compiled model\")\n",
    "    # Train the compiled model (note: the model will only be compiled once and then re-used for subsequent runs)\n",
    "    results = train_compiled_model(model=compiled_model, epochs=NUM_EPOCHS, disable_progress_bar=True)\n",
    "    compiled_results_multiple_runs.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_epoch_time</th>\n",
       "      <th>test_epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508540</td>\n",
       "      <td>0.819764</td>\n",
       "      <td>0.645157</td>\n",
       "      <td>0.800453</td>\n",
       "      <td>400.298736</td>\n",
       "      <td>101.883877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.330550</td>\n",
       "      <td>0.885723</td>\n",
       "      <td>0.584300</td>\n",
       "      <td>0.823383</td>\n",
       "      <td>402.354628</td>\n",
       "      <td>102.392826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.255531</td>\n",
       "      <td>0.911782</td>\n",
       "      <td>0.560945</td>\n",
       "      <td>0.838292</td>\n",
       "      <td>369.065357</td>\n",
       "      <td>104.916177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.206041</td>\n",
       "      <td>0.928470</td>\n",
       "      <td>0.575504</td>\n",
       "      <td>0.842585</td>\n",
       "      <td>355.319653</td>\n",
       "      <td>106.803499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.164079</td>\n",
       "      <td>0.942898</td>\n",
       "      <td>0.563964</td>\n",
       "      <td>0.850007</td>\n",
       "      <td>360.856686</td>\n",
       "      <td>105.348978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  test_loss  test_acc  train_epoch_time  \\\n",
       "0    0.508540   0.819764   0.645157  0.800453        400.298736   \n",
       "1    0.330550   0.885723   0.584300  0.823383        402.354628   \n",
       "2    0.255531   0.911782   0.560945  0.838292        369.065357   \n",
       "3    0.206041   0.928470   0.575504  0.842585        355.319653   \n",
       "4    0.164079   0.942898   0.563964  0.850007        360.856686   \n",
       "\n",
       "   test_epoch_time  \n",
       "0       101.883877  \n",
       "1       102.392826  \n",
       "2       104.916177  \n",
       "3       106.803499  \n",
       "4       105.348978  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through compile_results_multiple_runs and create a dataframe for each run then concatenate them together\n",
    "compile_results_dfs = []\n",
    "for result in compiled_results_multiple_runs:\n",
    "    result_df = pd.DataFrame(result)\n",
    "    compile_results_dfs.append(result_df)\n",
    "compile_results_multiple_runs_df = pd.concat(compile_results_dfs)\n",
    "\n",
    "# Get the averages across the multiple runs\n",
    "compile_results_multiple_runs_df = compile_results_multiple_runs_df.groupby(compile_results_multiple_runs_df.index).mean() # .index = groupby the epoch number\n",
    "compile_results_multiple_runs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4.3 Compare results of experiment 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train epoch time difference: -10.932% (negative means faster)\n",
      "Mean test epoch time difference: 3.373% (negative means faster)\n",
      "[INFO] Plot saved to pytorch_2_results/figures/multi_run_NVIDIA_GeForce_RTX_3050_Laptop_GPU_ResNet50_CIFAR10_128_train_epoch_time.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a directory to save the multi-run figure to \n",
    "os.makedirs(\"pytorch_2_results/figures\", exist_ok=True)\n",
    "\n",
    "# Create a path to save the figure for multiple runs\n",
    "save_path_multi_run = f\"pytorch_2_results/figures/multi_run_{GPU_NAME}_{MODEL_NAME}_{DATASET_NAME}_{IMAGE_SIZE}_train_epoch_time.png\"\n",
    "\n",
    "# Plot the mean epoch times for experiment 3 and 4\n",
    "plot_mean_epoch_times(non_compiled_results=non_compile_results_multiple_runs_df, \n",
    "                      compiled_results=compile_results_multiple_runs_df, \n",
    "                      multi_runs=True, \n",
    "                      num_runs=NUM_RUNS, \n",
    "                      save_path=save_path_multi_run, \n",
    "                      save=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ความหมายของผลลัพธ์:**  \n",
    "\n",
    "1. **Mean train epoch time difference: -10.932%**  \n",
    "   - เวลาเฉลี่ยในการฝึก (train) ของแต่ละ epoch ลดลง **10.932%** เมื่อเปรียบเทียบระหว่างโมเดลที่ใช้ **PyTorch 2.0 (compiled)** กับโมเดลแบบธรรมดา (non-compiled)  \n",
    "   - **ค่าลบ (negative)** หมายถึงโมเดลที่ถูก compile เร็วกว่า  \n",
    "\n",
    "2. **Mean test epoch time difference: 3.373%**  \n",
    "   - เวลาเฉลี่ยในการทดสอบ (test) ของแต่ละ epoch เพิ่มขึ้น **3.373%** เมื่อใช้โมเดลที่ compile  \n",
    "   - **ค่าบวก (positive)** หมายถึงการทดสอบ (test) ของโมเดลแบบ compile ใช้เวลานานกว่าเล็กน้อย  \n",
    "\n",
    "---\n",
    "\n",
    "### **สรุปผลโดยรวม:**  \n",
    "- **การฝึก (train)**: PyTorch 2.0 (compiled) ช่วยให้กระบวนการฝึกเร็วขึ้นประมาณ 10.932%  \n",
    "- **การทดสอบ (test)**: PyTorch 2.0 (compiled) อาจมี overhead เพิ่มขึ้นเล็กน้อยในขั้นตอนการทดสอบ  \n",
    "\n",
    "---\n",
    "\n",
    "### **สาเหตุที่การทดสอบช้าลง:**  \n",
    "1. **Overhead จากการ Optimize Model:**  \n",
    "   การ compile โมเดลอาจเพิ่มขั้นตอนในระหว่างการรัน (เช่น การ optimize graph)  \n",
    "2. **ขนาดข้อมูลใน Test:**  \n",
    "   หากข้อมูลในขั้นตอนการทดสอบมีขนาดเล็ก อาจไม่ได้ใช้ประสิทธิภาพของการ compile เต็มที่  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4.4 Save multi runs results to file with GPU details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving experiment 3 non-compiled results to: pytorch_2_results/multi_run_results/single_run_non_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_3050_Laptop_GPU.csv\n",
      "[INFO] Saving experiment 4 compiled results to: pytorch_2_results/multi_run_results/single_run_compiled_results_CIFAR10_ResNet50_NVIDIA_GeForce_RTX_3050_Laptop_GPU.csv\n"
     ]
    }
   ],
   "source": [
    "# Make a directory for multi_run results\n",
    "import os\n",
    "pytorch_2_results_dir = \"pytorch_2_results\"\n",
    "pytorch_2_multi_run_results_dir = f\"{pytorch_2_results_dir}/multi_run_results\"\n",
    "os.makedirs(pytorch_2_multi_run_results_dir, exist_ok=True)\n",
    "\n",
    "# Create filenames for each of the dataframes\n",
    "save_name_for_multi_run_non_compiled_results = f\"multi_run_non_compiled_results_{NUM_RUNS}_runs_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME}.csv\"\n",
    "save_name_for_multi_run_compiled_results = f\"multi_run_compiled_results_{NUM_RUNS}_runs_{DATASET_NAME}_{MODEL_NAME}_{GPU_NAME}.csv\"\n",
    "\n",
    "# Create filepaths to save the results to\n",
    "multi_run_no_compile_save_path = f\"{pytorch_2_multi_run_results_dir}/{save_name_for_non_compiled_results}\"\n",
    "multi_run_compile_save_path = f\"{pytorch_2_multi_run_results_dir}/{save_name_for_compiled_results}\"\n",
    "print(f\"[INFO] Saving experiment 3 non-compiled results to: {multi_run_no_compile_save_path}\")\n",
    "print(f\"[INFO] Saving experiment 4 compiled results to: {multi_run_compile_save_path}\")\n",
    "\n",
    "# Save the results\n",
    "non_compile_results_multiple_runs_df.to_csv(multi_run_no_compile_save_path)\n",
    "compile_results_multiple_runs_df.to_csv(multi_run_compile_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. การปรับปรุงและการขยายที่เป็นไปได้  \n",
    "\n",
    "1. **ใช้ CPU ที่ทรงพลังขึ้น**  \n",
    "   - ช่วยโหลดข้อมูลไปยัง GPU ได้เร็วขึ้น  \n",
    "   - ความเร็วสัมพัทธ์ (relative speedups) จะดีขึ้นเมื่อ GPU ถูกใช้งานเต็มประสิทธิภาพ  \n",
    "\n",
    "2. **ใช้การฝึกแบบ Mixed Precision**  \n",
    "   - ผสมระหว่าง float32 และ float16  \n",
    "   - ช่วยลดเวลาในการฝึกโมเดล  \n",
    "\n",
    "3. **ใช้โมเดลแบบ Transformer แทน Convolutional**  \n",
    "   - โมเดลแบบ Transformer อาจได้รับความเร็วสัมพัทธ์มากกว่าจากการ optimize  \n",
    "\n",
    "4. **ฝึกโมเดลนานขึ้น**  \n",
    "   - ยิ่งฝึกโมเดลนานขึ้น จะยิ่งได้รับประโยชน์จากการ optimize ของ `torch.compile()`  \n",
    "\n",
    "ดูเพิ่มเติมได้ที่: [Learn PyTorch](https://www.learnpytorch.io/pytorch_2_intro/#5-possible-improvements-and-extensions)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##6. Resources to learn more\n",
    "\n",
    "See here: https://www.learnpytorch.io/pytorch_2_intro/#6-resources-to-learn-more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
